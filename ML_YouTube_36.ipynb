{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN(II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-size:25px\">Neural Architecture ( Weight &#x2022; Bias )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture/ML_img_36_1.png\" alt=\"ML_img_36_1\" width=873 height=327>\n",
    "\n",
    "|     | Linear Regression | layer output | layer weight + bias |\n",
    "|:---:|:---:|:---:|:---|\n",
    "| <span style=\"font-size:15px\">은닉층</span> | $\\small{\\text{A1} \\cdot \\text{W}_\\text{ih} = \\text{Z2}}$ | $\\small{\\text{relu}(\\text{Z2} + \\text{b}_\\text{h}) = \\text{A2}}$ | <span style=\"color:#FE2E64; font-size:15px\">가중치</span> $\\small{\\textcolor{#FE2E64}{\\text{W}_\\text{ih}}}$: <span style=\"font-size:15px\"><span style=\"color:#FE2E64; text-decoration:underline; text-decoration-color:#FE2E64; text-underline-offset:5px;\">Applied to the data (A1) input </span>to the hidden layer </span> <br> <span style=\"color:#FE2E64; font-size:15px\">바이어스</span>$\\small{\\textcolor{#FE2E64}{\\text{b}_\\text{h}}}$: <span style=\"font-size:15px\">Each layer has only one bias value, <br> which is added to the hidden <span style=\"color:#FE2E64; text-decoration: underline; text-decoration-color: #FE2E64; text-underline-offset: 5px;\">layer linear regression output (Z2)</span></span> |\n",
    "| <span style=\"font-size:15px\">출력층</span> | $\\small{\\text{A2} = \\text{W}_\\text{ho} \\cdot \\text{Z3}}$ | $\\small{\\text{softmax}(\\text{Z3} + \\text{b}_o) = \\text{A3}}$ |  <span style=\"font-size:15px; color:#FE2E64\">가중치</span> $\\small{\\textcolor{#FE2E64}{\\text{W}_\\text{ho}}}$: <span style=\"font-size:15px\"><span style=\"color:#FE2E64; text-decoration: underline; text-decoration-color: #FE2E64; text-underline-offset: 5px;\">Applied to the data (A2) input </span>to the output layer</span> <br> <span style=\"font-size:15px; color:#FE2E64\">바이어스</span> $\\small{\\textcolor{#FE2E64}{\\text{b}_o}}$: <span style=\"font-size:15px\">Each layer has only one bias value, <br> which is added to the output <span style=\"color:#FE2E64; text-decoration: underline; text-decoration-color: #FE2E64; text-underline-offset: 5px;\">layer linear regression output (Z3)</span></span> |\n",
    "\n",
    "$\n",
    "\\boxed{\n",
    "    \\begin{array}{c}\n",
    "    \\qquad\\qquad\\qquad\\qquad\\quad\\;\\: \\textcolor{#FE2E64}{\\text{Bias }}\\text{can be defined as only one value for each layer,} \\qquad\\qquad\\qquad\\qquad\\quad\\;\\:\n",
    "    \\\\\n",
    "    \\textcolor{#FE2E64}{\\text{whereas weights }}\\text{are definded for each input data point entering the layer.}\n",
    "    \\end{array}\n",
    "}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-size:25px\">RNN Architecture ( Weight &#x2022; Bias )</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture/ML_img_36_2.png\" alt=\"ML_img_36_2\" width=873 height=327>\n",
    "\n",
    "|      |      |\n",
    "|:----:|:----|\n",
    "| Bias | $\\boxed{ \\: \\textcolor{#FE2E64}{\\text{hidden layer bias b}_\\text{h} / \\text{output layer bias b}_\\text{o}} \\: }$<br>Since each layer must have on bias, there are total of two biases: <br>the bias $\\textcolor{#FE2E64}{\\text{b}_\\text{n}}$ for the <span style=\"color:#FE2E64\">[hidden layer]</span> and the $\\textcolor{#FE2E64}{\\text{b}_\\text{o}}$ for the <span style=\"color:#FE2E64\">[output layer]</span> |\n",
    "| Weight | $\\boxed{ \\: \\textcolor{#FE2E64}{\\text{hidden layer weight W}_\\text{ih} \\text{W}_\\text{hh} / \\text{output layer bias, W}_\\text{ho}} \\: }$<br><span style=\"color:#FE2E64\">For the [hidden layer]</span>, the weight applied to the input data A1 is defined as $\\textcolor{#FE2E64}{\\text{W}_\\text{ih}}$, while the weight <br>applied to the past data H retained within the hidden layer using the recurrent structure is defined W_hh.<br><span style=\"color:#FE2E64\">For the [output layer]</span>, the weight applied to the input data A2 can be observed that there is only one <br>weight, $\\textcolor{#FE2E64}{\\text{W}_\\text{ho}}$|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-size:25px\">RNN Operation Principle - Ouantitative analysis</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture/ML_img_36_2.png\" alt=\"ML_img_36_2\" width=873 height=327>\n",
    "\n",
    "$\n",
    "\\boxed{\n",
    "    \\colorbox{yellow}{\\textcolor{black}{\\text{RNN operation principle for the 1st input data A1}}}\n",
    "}\n",
    "$\n",
    "\n",
    "|     | <span style=\"font-size:15px\">② LR</span> | <span style=\"font-size:15px; color:#FE2E64\">③ Summation</span> | <span style=\"font-size:15px\">④ Output</span> | <span style=\"font-size:15px; color:#FE2E64\">next H</span> $\\small{\\textcolor{#FE2E64}{(\\text{H}_\\text{next})}}$ | <span style=\"font-size:15px; color:#FE2E64\">current H</span> $\\small{\\textcolor{#FE2E64}{(\\text{H}_\\text{cur})}}$ |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| <span style=\"font-size:15px\">Hidden layer</span> | $\\small{\\text{A1}\\cdot\\text{W}_\\text{ih} = \\text{Z2}}$ | $\\small{\\textcolor{#FE2E64}{\\text{Z2}+\\text{H}_\\text{cur}\\cdot\\text{W}_\\text{hh}+\\text{b}_\\text{n} =\\text{R2}}}$ | $\\small{\\text{tanh(R2) = A2}}$ | $\\small{\\text{A2}_\\text{cur}}$ | $\\small{\\text{0}}$ |\n",
    "\n",
    "<br>\n",
    "\n",
    "|     | <span style=\"font-size:15px\">⑤ LR</span> | <span style=\"font-size:15px\">⑥ Output</span> |\n",
    "|:---:|:---:|:---:|\n",
    "| <span style=\"font-size:15px\">Output layer</span> | $\\small{\\text{A2}\\cdot\\text{W}_\\text{ho} = \\text{Z3}}$ | $\\small{\\text{softmax(Z3 + b}_\\text{o}) = \\text{A3}}$ |\n",
    "\n",
    "<br><br>\n",
    "\n",
    "$\n",
    "\\boxed{\n",
    "    \\colorbox{yellow}{\\textcolor{black}{\\text{RNN operation principle for the 1st input data A1}}}\n",
    "}\n",
    "$\n",
    "\n",
    "|     | <span style=\"font-size:15px\">② LR</span> | <span style=\"font-size:15px; color:#FE2E64\">③ Summation</span> | <span style=\"font-size:15px\">④ Output</span> | <span style=\"font-size:15px; color:#FE2E64\">next H</span> $\\small{\\textcolor{#FE2E64}{(\\text{H}_\\text{next})}}$ | <span style=\"font-size:15px; color:#FE2E64\">current H</span> $\\small{\\textcolor{#FE2E64}{(\\text{H}_\\text{cur})}}$ |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| <span style=\"font-size:15px\">Hidden layer</span> | $\\small{\\text{A1}\\cdot\\text{W}_\\text{ih} = \\text{Z2}}$ | $\\small{\\textcolor{#FE2E64}{\\text{Z2}+\\text{H}_\\text{cur}\\cdot\\text{W}_\\text{hh}+\\text{b}_\\text{n} =\\text{R2}}}$ | $\\small{\\text{tanh(R2) = A2}}$ | $\\small{\\text{A2}_\\text{cur}}$ | $\\small{\\text{A2}_\\text{prev}}$ |\n",
    "\n",
    "<br>\n",
    "\n",
    "|     | <span style=\"font-size:15px\">⑤ LR</span> | <span style=\"font-size:15px\">⑥ Output</span> |\n",
    "|:---:|:---:|:---:|\n",
    "| <span style=\"font-size:15px\">Output layer</span> | $\\small{\\text{A2}\\cdot\\text{W}_\\text{ho} = \\text{Z3}}$ | $\\small{\\text{softmax(Z3 + b}_\\text{o}) = \\text{A3}}$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-size:25px\">RNN Operation Principle - Ouantitative analysis (current state)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture/ML_img_36_2.png\" alt=\"ML_img_36_2\" width=873 height=327>\n",
    "\n",
    "Z2 = A1&#x2022;$\\text{W}_\\text{ih} + \\text{b}_\\text{h}$\n",
    "\n",
    "R2 = Z2 + $\\text{H}_\\text{t-1} \\cdot \\text{W}_\\text{hh}$\n",
    "   = A1&#x2022;$\\text{W}_\\text{ih} + \\text{H}_\\text{t-1} \\cdot \\text{W}_\\text{hh} + \\text{b}_\\text{h}$\n",
    "\n",
    "\n",
    "<img src=\"picture/ML_img_36_3.png\" alt=\"ML_img_36_3\" width=900 height=250>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
