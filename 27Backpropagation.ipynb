{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.max(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backpropagation:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        self.__input_nodes = input_nodes\n",
    "        self.__hidden_nodes = hidden_nodes\n",
    "        self.__output_nodes = output_nodes\n",
    "\n",
    "\n",
    "        self.__W2 = (np.random.randn(self.__input_nodes, self.__hidden_nodes) / \n",
    "                     np.sqrt(self.__input_nodes))\n",
    "        self.__b2 = np.random.rand(self.__hidden_nodes)\n",
    "        \n",
    "        self.__W3 = (np.random.randn(self.__hidden_nodes, self.__output_nodes) / \n",
    "                     np.sqrt(self.__hidden_nodes))\n",
    "        self.__b3 = np.random.rand(self.__output_nodes)\n",
    "\n",
    "\n",
    "        self.__Z3 = np.zeros([1, output_nodes])\n",
    "        self.__A3 = np.zeros([1, output_nodes])\n",
    "        \n",
    "        self.__Z2 = np.zeros([1, hidden_nodes])\n",
    "        self.__A2 = np.zeros([1, hidden_nodes])\n",
    "        \n",
    "        self.__Z1 = np.zeros([1, input_nodes])\n",
    "        self.__A1 = np.zeros([1, input_nodes])\n",
    "\n",
    "        self.__learning_rate = learning_rate\n",
    "\n",
    "    def __feed_forward(self):\n",
    "        delta = 1e-7\n",
    "\n",
    "        self.__Z1 = self.__input_data\n",
    "        self.__A1 = self.__input_data\n",
    "\n",
    "        self.__Z2 = np.dot(self.__A1, self.__W2) + self.__b2\n",
    "        self.__A2 = sigmoid(self.__Z2)\n",
    "\n",
    "        self.__Z3 = np.dot(self.__A2, self.__W3) + self.__b3\n",
    "        self.__A3 = sigmoid(self.__Z3)\n",
    "\n",
    "        return -np.sum(self.__target_data * np.log(self.__A3 + delta) + \n",
    "                       (1 - self.__target_data) * np.log((1 - self.__A3) + delta))\n",
    "    \n",
    "    def loss_val(self):\n",
    "        delta = 1e-7\n",
    "\n",
    "        self.__Z1 = self.__input_data\n",
    "        self.__A1 = self.__input_data\n",
    "\n",
    "        self.__Z2 = np.dot(self.__A1, self.__W2) + self.__b2\n",
    "        self.__A2 = sigmoid(self.__Z2)\n",
    "\n",
    "        self.__Z3 = np.dot(self.__A2, self.__W3) + self.__b3\n",
    "        self.__A3 = sigmoid(self.__Z3)\n",
    "\n",
    "        return -np.sum(self.__target_data * np.log(self.__A3 + delta) + \n",
    "                       (1 - self.__target_data) * np.log((1 - self.__A3) + delta))\n",
    "    \n",
    "    def train(self, input_data, target_data):\n",
    "        self.__input_data = input_data\n",
    "        self.__target_data = target_data\n",
    "\n",
    "        loss_val = self.__feed_forward()\n",
    "\n",
    "        loss_3 = (self.__A3 - self.__target_data) * self.__A3 * (1 - self.__A3)\n",
    "\n",
    "        self.__W3 -= self.__learning_rate * np.dot(self.__A2.T, loss_3)\n",
    "        self.__b3 = self.__b3 - self.__learning_rate * loss_3\n",
    "\n",
    "        loss_2 = np.dot(loss_3, self.__W3.T) * self.__A2 * (1 - self.__A2)\n",
    "\n",
    "        self.__W2 -= self.__learning_rate * np.dot(self.__A1.T, loss_2)\n",
    "        self.__b2 = self.__b2 - self.__learning_rate * loss_2\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        Z2 = np.dot(input_data, self.__W2) + self.__b2\n",
    "        A2 = sigmoid(Z2)\n",
    "\n",
    "        Z3 = np.dot(A2, self.__W3) + self.__b3\n",
    "        A3 = sigmoid(Z3)\n",
    "\n",
    "        predicted_num = np.argmax(A3)\n",
    "\n",
    "        return predicted_num\n",
    "    \n",
    "    def accuracy(self, test_data):\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "\n",
    "        for index in range(len(test_data)):\n",
    "            label = int(test_data[index, 0])\n",
    "            data = (test_data[index, 1:] / 255.0 * 0.99) + 0.01\n",
    "            predicted_num = self.predict(np.array(data, ndmin=2))\n",
    "\n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "\n",
    "        print(\"Current a accuracy =\", 100 * len(matched_list) / len(test_data), \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.loadtxt(r\"C:\\Users\\skygr\\OneDrive\\바탕 화면\\mnist_train.csv\", delimiter=',', \n",
    "                           dtype=np.float32, encoding='utf-8')\n",
    "test_data = np.loadtxt(r\"C:\\Users\\skygr\\OneDrive\\바탕 화면\\mnist_test.csv\", delimiter=',', \n",
    "                           dtype=np.float32, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 , loss value = 2.8961957928038853\n",
      "step = 400 , loss value = 2.386611055187281\n",
      "step = 800 , loss value = 1.4866808735006778\n",
      "step = 1200 , loss value = 0.7207881346550153\n",
      "step = 1600 , loss value = 0.8467221851315764\n",
      "step = 2000 , loss value = 2.6404209416330215\n",
      "step = 2400 , loss value = 0.713459891244779\n",
      "step = 2800 , loss value = 1.7586013122977187\n",
      "step = 3200 , loss value = 0.8056715136744743\n",
      "step = 3600 , loss value = 0.7101549275638553\n",
      "step = 4000 , loss value = 0.9222628237650018\n",
      "step = 4400 , loss value = 0.8013073897919606\n",
      "step = 4800 , loss value = 0.9367504413766764\n",
      "step = 5200 , loss value = 0.7682449462575855\n",
      "step = 5600 , loss value = 0.9337635522988033\n",
      "step = 6000 , loss value = 0.8012732102121636\n",
      "step = 6400 , loss value = 0.9289875932961269\n",
      "step = 6800 , loss value = 0.9016592821487108\n",
      "step = 7200 , loss value = 0.7927896485515307\n",
      "step = 7600 , loss value = 0.8725172453412727\n",
      "step = 8000 , loss value = 0.9596275814266108\n",
      "step = 8400 , loss value = 0.7994013794809621\n",
      "step = 8800 , loss value = 0.9126562556411584\n",
      "step = 9200 , loss value = 0.8627021226919118\n",
      "step = 9600 , loss value = 0.9355302037783704\n",
      "step = 10000 , loss value = 0.958339458529424\n",
      "step = 10400 , loss value = 0.9680833948585227\n",
      "step = 10800 , loss value = 2.2729732249218215\n",
      "step = 11200 , loss value = 0.9024901856999862\n",
      "step = 11600 , loss value = 13.708038309121058\n",
      "step = 12000 , loss value = 0.8884425713426926\n",
      "step = 12400 , loss value = 0.9015526844715744\n",
      "step = 12800 , loss value = 0.9073944479282238\n",
      "step = 13200 , loss value = 0.986950249693223\n",
      "step = 13600 , loss value = 0.9886705863869951\n",
      "step = 14000 , loss value = 0.9923891959192788\n",
      "step = 14400 , loss value = 0.986909554940699\n",
      "step = 14800 , loss value = 0.9619993811702449\n",
      "step = 15200 , loss value = 1.0870319865266602\n",
      "step = 15600 , loss value = 1.0520777737311922\n",
      "step = 16000 , loss value = 1.014199758051881\n",
      "step = 16400 , loss value = 0.9834900612804294\n",
      "step = 16800 , loss value = 1.1284738426254803\n",
      "step = 17200 , loss value = 0.9993910072084362\n",
      "step = 17600 , loss value = 1.0077611872558139\n",
      "step = 18000 , loss value = 0.9991470080006839\n",
      "step = 18400 , loss value = 0.8623673590720388\n",
      "step = 18800 , loss value = 0.919835841081329\n",
      "step = 19200 , loss value = 1.0188573534997525\n",
      "step = 19600 , loss value = 0.9506391282777267\n",
      "step = 20000 , loss value = 0.9852624769762391\n",
      "step = 20400 , loss value = 1.0026041165222268\n",
      "step = 20800 , loss value = 1.1456981770269759\n",
      "step = 21200 , loss value = 0.8821725544762374\n",
      "step = 21600 , loss value = 1.0730686988132707\n",
      "step = 22000 , loss value = 1.0178743134897563\n",
      "step = 22400 , loss value = 0.9636278668780949\n",
      "step = 22800 , loss value = 0.9801020147679442\n",
      "step = 23200 , loss value = 1.0331234331381045\n",
      "step = 23600 , loss value = 1.0301438883659337\n",
      "step = 24000 , loss value = 1.0163561863152077\n",
      "step = 24400 , loss value = 1.0368028368893834\n",
      "step = 24800 , loss value = 0.963048171372581\n",
      "step = 25200 , loss value = 0.9801781920728136\n",
      "step = 25600 , loss value = 0.9157113683301977\n",
      "step = 26000 , loss value = 1.0131878111135053\n",
      "step = 26400 , loss value = 1.1097285892721709\n",
      "step = 26800 , loss value = 1.143447167253861\n",
      "step = 27200 , loss value = 1.0930185438242128\n",
      "step = 27600 , loss value = 1.111623949249151\n",
      "step = 28000 , loss value = 0.9753539291631477\n",
      "step = 28400 , loss value = 1.1443125455284187\n",
      "step = 28800 , loss value = 1.0075389317280998\n",
      "step = 29200 , loss value = 1.0433035428206572\n",
      "step = 29600 , loss value = 1.1012647246366327\n",
      "step = 30000 , loss value = 1.1202969753831056\n",
      "step = 30400 , loss value = 0.9929435987634423\n",
      "step = 30800 , loss value = 1.1264223041361354\n",
      "step = 31200 , loss value = 12.1671745112504\n",
      "step = 31600 , loss value = 6.376944772917488\n",
      "step = 32000 , loss value = 0.9801914455159678\n",
      "step = 32400 , loss value = 1.0011599247634708\n",
      "step = 32800 , loss value = 1.0887332392795293\n",
      "step = 33200 , loss value = 1.2059754994942908\n",
      "step = 33600 , loss value = 1.0259623275840701\n",
      "step = 34000 , loss value = 1.0870248850330078\n",
      "step = 34400 , loss value = 1.119351632192344\n",
      "step = 34800 , loss value = 6.869158532216431\n",
      "step = 35200 , loss value = 1.1028169272464454\n",
      "step = 35600 , loss value = 0.9488565473939707\n",
      "step = 36000 , loss value = 1.0530172125214001\n",
      "step = 36400 , loss value = 1.123009413492788\n",
      "step = 36800 , loss value = 1.1285800741316299\n",
      "step = 37200 , loss value = 1.0577904100647946\n",
      "step = 37600 , loss value = 1.037263638131464\n",
      "step = 38000 , loss value = 1.002674648666028\n",
      "step = 38400 , loss value = 1.2201916856287969\n",
      "step = 38800 , loss value = 1.0719751703553544\n",
      "step = 39200 , loss value = 1.1805087536067251\n",
      "step = 39600 , loss value = 6.194577664891784\n",
      "step = 40000 , loss value = 1.116241708113861\n",
      "step = 40400 , loss value = 1.2199537276290326\n",
      "step = 40800 , loss value = 1.079931683425021\n",
      "step = 41200 , loss value = 1.047422522706412\n",
      "step = 41600 , loss value = 0.998403786976518\n",
      "step = 42000 , loss value = 0.9944532417825158\n",
      "step = 42400 , loss value = 1.0703437541941612\n",
      "step = 42800 , loss value = 1.1457882886536552\n",
      "step = 43200 , loss value = 1.0762834951149998\n",
      "step = 43600 , loss value = 0.9609843084829225\n",
      "step = 44000 , loss value = 1.1704636376246165\n",
      "step = 44400 , loss value = 1.10678934090784\n",
      "step = 44800 , loss value = 0.9963768715374148\n",
      "step = 45200 , loss value = 1.241437346596557\n",
      "step = 45600 , loss value = 1.0252270820902296\n",
      "step = 46000 , loss value = 1.152242609552308\n",
      "step = 46400 , loss value = 1.122505922832434\n",
      "step = 46800 , loss value = 1.1045156973734758\n",
      "step = 47200 , loss value = 1.0303721952933196\n",
      "step = 47600 , loss value = 1.2340068481541353\n",
      "step = 48000 , loss value = 1.1684380248968778\n",
      "step = 48400 , loss value = 1.2190594099510195\n",
      "step = 48800 , loss value = 1.037071977656998\n",
      "step = 49200 , loss value = 1.2009842296475044\n",
      "step = 49600 , loss value = 1.0736410432048389\n",
      "step = 50000 , loss value = 1.102837652409417\n",
      "step = 50400 , loss value = 1.033493214152219\n",
      "step = 50800 , loss value = 1.1690465346551657\n",
      "step = 51200 , loss value = 3.130610972439893\n",
      "step = 51600 , loss value = 9.746141012945907\n",
      "step = 52000 , loss value = 1.0948032026578043\n",
      "step = 52400 , loss value = 1.1719605359487537\n",
      "step = 52800 , loss value = 4.908129307093592\n",
      "step = 53200 , loss value = 1.1165419066837996\n",
      "step = 53600 , loss value = 1.1495828832317354\n",
      "step = 54000 , loss value = 1.1910130531764995\n",
      "step = 54400 , loss value = 1.1592779546302925\n",
      "step = 54800 , loss value = 1.2111440040522206\n",
      "step = 55200 , loss value = 1.1104638844626722\n",
      "step = 55600 , loss value = 1.053024259445603\n",
      "step = 56000 , loss value = 1.0095015417153006\n",
      "step = 56400 , loss value = 1.12912343527177\n",
      "step = 56800 , loss value = 15.679792714910262\n",
      "step = 57200 , loss value = 1.101672669890922\n",
      "step = 57600 , loss value = 1.1920232237213322\n",
      "step = 58000 , loss value = 1.1363512163708078\n",
      "step = 58400 , loss value = 1.0318677626099868\n",
      "step = 58800 , loss value = 1.1138080879947374\n",
      "step = 59200 , loss value = 1.0623582288809081\n",
      "step = 59600 , loss value = 1.194536455843161\n",
      "step = 0 , loss value = 1.1826099695218855\n",
      "step = 400 , loss value = 1.2335894000383778\n",
      "step = 800 , loss value = 1.0855393408532366\n",
      "step = 1200 , loss value = 1.0619849577249738\n",
      "step = 1600 , loss value = 1.1801855531492864\n",
      "step = 2000 , loss value = 1.488389491910824\n",
      "step = 2400 , loss value = 1.151766481362888\n",
      "step = 2800 , loss value = 1.1325986928192509\n",
      "step = 3200 , loss value = 1.1904741920585464\n",
      "step = 3600 , loss value = 1.0819019823006253\n",
      "step = 4000 , loss value = 1.1894714269379285\n",
      "step = 4400 , loss value = 1.1516613340852493\n",
      "step = 4800 , loss value = 1.937176440779264\n",
      "step = 5200 , loss value = 1.0985532706979326\n",
      "step = 5600 , loss value = 1.103980512380238\n",
      "step = 6000 , loss value = 1.2374237849599423\n",
      "step = 6400 , loss value = 1.223493097007455\n",
      "step = 6800 , loss value = 1.1557373784781146\n",
      "step = 7200 , loss value = 0.9849619194437974\n",
      "step = 7600 , loss value = 1.141509098220199\n",
      "step = 8000 , loss value = 1.2596556751918206\n",
      "step = 8400 , loss value = 1.0251655037390695\n",
      "step = 8800 , loss value = 1.2063777867775793\n",
      "step = 9200 , loss value = 1.2383240746114053\n",
      "step = 9600 , loss value = 1.2789421977250934\n",
      "step = 10000 , loss value = 1.2375130313937854\n",
      "step = 10400 , loss value = 1.043344929671811\n",
      "step = 10800 , loss value = 1.0645870015349033\n",
      "step = 11200 , loss value = 1.0880455149362378\n",
      "step = 11600 , loss value = 11.351875988217188\n",
      "step = 12000 , loss value = 1.1815858931245358\n",
      "step = 12400 , loss value = 1.0166635382443419\n",
      "step = 12800 , loss value = 1.0992562587522612\n",
      "step = 13200 , loss value = 1.0440424618145663\n",
      "step = 13600 , loss value = 1.3162081892555235\n",
      "step = 14000 , loss value = 1.1191657593649786\n",
      "step = 14400 , loss value = 1.1202616159632828\n",
      "step = 14800 , loss value = 1.1198715641823744\n",
      "step = 15200 , loss value = 1.306902726809233\n",
      "step = 15600 , loss value = 1.2357922387807834\n",
      "step = 16000 , loss value = 1.1315187020804915\n",
      "step = 16400 , loss value = 1.167687203334211\n",
      "step = 16800 , loss value = 1.2327364169172923\n",
      "step = 17200 , loss value = 1.0799460905250573\n",
      "step = 17600 , loss value = 1.1811591800914882\n",
      "step = 18000 , loss value = 1.1668027349125067\n",
      "step = 18400 , loss value = 1.0949323782670701\n",
      "step = 18800 , loss value = 1.1632621985820197\n",
      "step = 19200 , loss value = 1.1823098301341908\n",
      "step = 19600 , loss value = 1.1104260739020213\n",
      "step = 20000 , loss value = 1.1652827608861138\n",
      "step = 20400 , loss value = 1.1980416167188417\n",
      "step = 20800 , loss value = 1.1908393812023137\n",
      "step = 21200 , loss value = 1.067555352336914\n",
      "step = 21600 , loss value = 1.1775509640177055\n",
      "step = 22000 , loss value = 1.2165954330791118\n",
      "step = 22400 , loss value = 1.0477158092492236\n",
      "step = 22800 , loss value = 1.1225422579903577\n",
      "step = 23200 , loss value = 1.1275046859452738\n",
      "step = 23600 , loss value = 1.1145228657015247\n",
      "step = 24000 , loss value = 1.1914933745487044\n",
      "step = 24400 , loss value = 1.2627185888160377\n",
      "step = 24800 , loss value = 1.073152890435714\n",
      "step = 25200 , loss value = 1.0587951488279845\n",
      "step = 25600 , loss value = 1.100402536647527\n",
      "step = 26000 , loss value = 1.149989405241525\n",
      "step = 26400 , loss value = 1.2243420359009165\n",
      "step = 26800 , loss value = 1.2538304245064318\n",
      "step = 27200 , loss value = 1.151396947659244\n",
      "step = 27600 , loss value = 1.2647594858382605\n",
      "step = 28000 , loss value = 1.0917346382202218\n",
      "step = 28400 , loss value = 1.2731478576956987\n",
      "step = 28800 , loss value = 1.1575736758535504\n",
      "step = 29200 , loss value = 1.2143476715987482\n",
      "step = 29600 , loss value = 1.1375777402358884\n",
      "step = 30000 , loss value = 1.2094315766427615\n",
      "step = 30400 , loss value = 1.0860838414230685\n",
      "step = 30800 , loss value = 1.2080163026603787\n",
      "step = 31200 , loss value = 7.225187735443264\n",
      "step = 31600 , loss value = 2.9446655266720008\n",
      "step = 32000 , loss value = 1.091713709012056\n",
      "step = 32400 , loss value = 1.1217466453847564\n",
      "step = 32800 , loss value = 1.1911113587808602\n",
      "step = 33200 , loss value = 1.1542077983827417\n",
      "step = 33600 , loss value = 1.091875809679231\n",
      "step = 34000 , loss value = 1.167438362179162\n",
      "step = 34400 , loss value = 1.1973881215261029\n",
      "step = 34800 , loss value = 4.618000743026162\n",
      "step = 35200 , loss value = 1.2562238870521822\n",
      "step = 35600 , loss value = 1.072365101849417\n",
      "step = 36000 , loss value = 1.0519951528125009\n",
      "step = 36400 , loss value = 1.2179614778772685\n",
      "step = 36800 , loss value = 1.1085936492843647\n",
      "step = 37200 , loss value = 1.1239855487919297\n",
      "step = 37600 , loss value = 1.0913904367235019\n",
      "step = 38000 , loss value = 1.1431682066093565\n",
      "step = 38400 , loss value = 1.2841547299454277\n",
      "step = 38800 , loss value = 1.159849098747192\n",
      "step = 39200 , loss value = 1.2567301870178245\n",
      "step = 39600 , loss value = 5.383448396107687\n",
      "step = 40000 , loss value = 1.2416659480039776\n",
      "step = 40400 , loss value = 1.2307672368290816\n",
      "step = 40800 , loss value = 1.1241722450519658\n",
      "step = 41200 , loss value = 1.1010368555864738\n",
      "step = 41600 , loss value = 1.131874607007944\n",
      "step = 42000 , loss value = 1.1449933655128501\n",
      "step = 42400 , loss value = 1.1928213600851565\n",
      "step = 42800 , loss value = 1.2352154501902106\n",
      "step = 43200 , loss value = 1.2501397948191284\n",
      "step = 43600 , loss value = 1.1012147905847685\n",
      "step = 44000 , loss value = 1.3136636088188722\n",
      "step = 44400 , loss value = 1.2334547160113245\n",
      "step = 44800 , loss value = 1.0126231101542578\n",
      "step = 45200 , loss value = 1.4098836915658004\n",
      "step = 45600 , loss value = 1.1976692436850087\n",
      "step = 46000 , loss value = 1.2190020774646395\n",
      "step = 46400 , loss value = 1.1994786061942566\n",
      "step = 46800 , loss value = 1.1914013181493621\n",
      "step = 47200 , loss value = 1.1729509406865137\n",
      "step = 47600 , loss value = 9.55199712930759\n",
      "step = 48000 , loss value = 1.2204947429689474\n",
      "step = 48400 , loss value = 1.277684808064051\n",
      "step = 48800 , loss value = 1.1010000909926738\n",
      "step = 49200 , loss value = 1.139548566352933\n",
      "step = 49600 , loss value = 1.0775303149447824\n",
      "step = 50000 , loss value = 1.16589051418446\n",
      "step = 50400 , loss value = 1.1311054422652445\n",
      "step = 50800 , loss value = 1.197741860546022\n",
      "step = 51200 , loss value = 1.187919761092662\n",
      "step = 51600 , loss value = 3.2642048542627227\n",
      "step = 52000 , loss value = 1.1746039475029368\n",
      "step = 52400 , loss value = 1.3607872852727838\n",
      "step = 52800 , loss value = 5.275542445706696\n",
      "step = 53200 , loss value = 1.2233009122070388\n",
      "step = 53600 , loss value = 1.1206926410010216\n",
      "step = 54000 , loss value = 1.2420680642474982\n",
      "step = 54400 , loss value = 1.2187182688010343\n",
      "step = 54800 , loss value = 1.26609263358223\n",
      "step = 55200 , loss value = 1.182167379352437\n",
      "step = 55600 , loss value = 1.1761626106969982\n",
      "step = 56000 , loss value = 1.070925645065878\n",
      "step = 56400 , loss value = 1.180961972779347\n",
      "step = 56800 , loss value = 15.953933083528542\n",
      "step = 57200 , loss value = 1.185147987861044\n",
      "step = 57600 , loss value = 1.2401757830675633\n",
      "step = 58000 , loss value = 1.1860180075583857\n",
      "step = 58400 , loss value = 1.1802784917971452\n",
      "step = 58800 , loss value = 1.2350104827369164\n",
      "step = 59200 , loss value = 1.1444840218688512\n",
      "step = 59600 , loss value = 1.2225366989496451\n",
      "step = 0 , loss value = 1.2269613730066553\n",
      "step = 400 , loss value = 1.3321924248827048\n",
      "step = 800 , loss value = 1.1464696063254212\n",
      "step = 1200 , loss value = 1.1350794802474415\n",
      "step = 1600 , loss value = 1.1707849065651634\n",
      "step = 2000 , loss value = 1.453405528725953\n",
      "step = 2400 , loss value = 1.219515382966952\n",
      "step = 2800 , loss value = 1.152075025859865\n",
      "step = 3200 , loss value = 1.243137241625195\n",
      "step = 3600 , loss value = 1.0937573466342467\n",
      "step = 4000 , loss value = 1.2412937874793235\n",
      "step = 4400 , loss value = 1.278323022647759\n",
      "step = 4800 , loss value = 1.0795097438676735\n",
      "step = 5200 , loss value = 1.0607837469672494\n",
      "step = 5600 , loss value = 1.665042424863205\n",
      "step = 6000 , loss value = 1.3149972663524974\n",
      "step = 6400 , loss value = 1.2819484749898309\n",
      "step = 6800 , loss value = 1.2335650235272182\n",
      "step = 7200 , loss value = 1.0886609707186616\n",
      "step = 7600 , loss value = 1.3175788531811765\n",
      "step = 8000 , loss value = 1.2954433242040715\n",
      "step = 8400 , loss value = 1.0702794367979946\n",
      "step = 8800 , loss value = 1.210857741740857\n",
      "step = 9200 , loss value = 1.2768933775056812\n",
      "step = 9600 , loss value = 1.334399016091725\n",
      "step = 10000 , loss value = 1.3837130059852547\n",
      "step = 10400 , loss value = 1.0927532355634695\n",
      "step = 10800 , loss value = 1.1652735660089881\n",
      "step = 11200 , loss value = 1.112733354731965\n",
      "step = 11600 , loss value = 9.710426903140984\n",
      "step = 12000 , loss value = 1.1591580859371013\n",
      "step = 12400 , loss value = 1.0905715929894042\n",
      "step = 12800 , loss value = 1.2003442021216164\n",
      "step = 13200 , loss value = 1.2075919265951334\n",
      "step = 13600 , loss value = 1.3230923264683816\n",
      "step = 14000 , loss value = 1.1597101139856794\n",
      "step = 14400 , loss value = 1.2420384594676612\n",
      "step = 14800 , loss value = 1.2217273779236657\n",
      "step = 15200 , loss value = 1.4083210556418635\n",
      "step = 15600 , loss value = 1.3106666024187568\n",
      "step = 16000 , loss value = 1.2022923801377556\n",
      "step = 16400 , loss value = 1.2955051955407897\n",
      "step = 16800 , loss value = 1.2990672356415733\n",
      "step = 17200 , loss value = 1.1523317080704085\n",
      "step = 17600 , loss value = 1.181172988090728\n",
      "step = 18000 , loss value = 1.1557341776748005\n",
      "step = 18400 , loss value = 1.0944221924449296\n",
      "step = 18800 , loss value = 1.1439498148663654\n",
      "step = 19200 , loss value = 1.2240299663838392\n",
      "step = 19600 , loss value = 1.145245159521076\n",
      "step = 20000 , loss value = 1.2077960952137345\n",
      "step = 20400 , loss value = 1.3811892768014762\n",
      "step = 20800 , loss value = 1.3333183103023571\n",
      "step = 21200 , loss value = 1.1436444039803717\n",
      "step = 21600 , loss value = 1.2998129582108375\n",
      "step = 22000 , loss value = 1.233591316419985\n",
      "step = 22400 , loss value = 1.1616112357804544\n",
      "step = 22800 , loss value = 1.1682993366436216\n",
      "step = 23200 , loss value = 1.208084769247087\n",
      "step = 23600 , loss value = 1.1700375424270693\n",
      "step = 24000 , loss value = 1.1428673893442447\n",
      "step = 24400 , loss value = 1.2742075248480762\n",
      "step = 24800 , loss value = 1.1161995122025274\n",
      "step = 25200 , loss value = 1.141830016863481\n",
      "step = 25600 , loss value = 1.0993641967496508\n",
      "step = 26000 , loss value = 1.2118356196238707\n",
      "step = 26400 , loss value = 1.3211235406178896\n",
      "step = 26800 , loss value = 1.3230638931411318\n",
      "step = 27200 , loss value = 1.1287462216868207\n",
      "step = 27600 , loss value = 1.333119846254128\n",
      "step = 28000 , loss value = 1.182962713266173\n",
      "step = 28400 , loss value = 1.3162321075779841\n",
      "step = 28800 , loss value = 1.1636092632709503\n",
      "step = 29200 , loss value = 1.3042473144054698\n",
      "step = 29600 , loss value = 1.234105527801563\n",
      "step = 30000 , loss value = 1.30457409291026\n",
      "step = 30400 , loss value = 1.1410619500724375\n",
      "step = 30800 , loss value = 1.222057482239007\n",
      "step = 31200 , loss value = 1.1834861269253174\n",
      "step = 31600 , loss value = 1.0445379602158424\n",
      "step = 32000 , loss value = 1.1035091874289449\n",
      "step = 32400 , loss value = 1.110929647355568\n",
      "step = 32800 , loss value = 1.339101515366405\n",
      "step = 33200 , loss value = 1.2041921646014657\n",
      "step = 33600 , loss value = 1.2170176062048323\n",
      "step = 34000 , loss value = 1.2130033121130597\n",
      "step = 34400 , loss value = 1.2735869451716921\n",
      "step = 34800 , loss value = 1.1445949638968393\n",
      "step = 35200 , loss value = 1.268683410492954\n",
      "step = 35600 , loss value = 1.1627854343735207\n",
      "step = 36000 , loss value = 1.060723280221644\n",
      "step = 36400 , loss value = 1.2553803761336007\n",
      "step = 36800 , loss value = 1.2063339718275445\n",
      "step = 37200 , loss value = 1.1573873425018524\n",
      "step = 37600 , loss value = 1.1029083417007324\n",
      "step = 38000 , loss value = 1.1830192137125668\n",
      "step = 38400 , loss value = 1.3005622561868304\n",
      "step = 38800 , loss value = 1.2154675746884709\n",
      "step = 39200 , loss value = 1.2782938632409708\n",
      "step = 39600 , loss value = 5.316646428642574\n",
      "step = 40000 , loss value = 1.2694556750027572\n",
      "step = 40400 , loss value = 1.257318066413057\n",
      "step = 40800 , loss value = 1.2477264574875013\n",
      "step = 41200 , loss value = 1.2019747851345146\n",
      "step = 41600 , loss value = 1.169513470135964\n",
      "step = 42000 , loss value = 1.197223106790187\n",
      "step = 42400 , loss value = 1.1237902096426853\n",
      "step = 42800 , loss value = 1.3359623179033977\n",
      "step = 43200 , loss value = 1.2365933002907832\n",
      "step = 43600 , loss value = 1.193805980086195\n",
      "step = 44000 , loss value = 1.2876935071139737\n",
      "step = 44400 , loss value = 1.26827033641811\n",
      "step = 44800 , loss value = 1.1323902180743841\n",
      "step = 45200 , loss value = 1.4322943813209554\n",
      "step = 45600 , loss value = 1.2930739134180413\n",
      "step = 46000 , loss value = 1.2767174808612196\n",
      "step = 46400 , loss value = 1.1710236072949463\n",
      "step = 46800 , loss value = 1.209886815360952\n",
      "step = 47200 , loss value = 1.197295995803908\n",
      "step = 47600 , loss value = 9.164272949686458\n",
      "step = 48000 , loss value = 1.199865329434814\n",
      "step = 48400 , loss value = 1.3551841046634823\n",
      "step = 48800 , loss value = 1.1465488503711907\n",
      "step = 49200 , loss value = 1.158003350727775\n",
      "step = 49600 , loss value = 1.101913352715856\n",
      "step = 50000 , loss value = 1.201134691736617\n",
      "step = 50400 , loss value = 1.1756154017587979\n",
      "step = 50800 , loss value = 1.3916983508281504\n",
      "step = 51200 , loss value = 1.1083150095827\n",
      "step = 51600 , loss value = 1.200528977925981\n",
      "step = 52000 , loss value = 1.1426463143108851\n",
      "step = 52400 , loss value = 1.4188277917637417\n",
      "step = 52800 , loss value = 6.825643664707434\n",
      "step = 53200 , loss value = 1.2692826459791722\n",
      "step = 53600 , loss value = 1.1501411027596777\n",
      "step = 54000 , loss value = 1.2616455773265844\n",
      "step = 54400 , loss value = 1.1811904274012974\n",
      "step = 54800 , loss value = 1.3040127692509877\n",
      "step = 55200 , loss value = 1.2132489445243586\n",
      "step = 55600 , loss value = 1.2996105645554157\n",
      "step = 56000 , loss value = 1.123016834196479\n",
      "step = 56400 , loss value = 1.244140860780113\n",
      "step = 56800 , loss value = 16.76038126660457\n",
      "step = 57200 , loss value = 1.2368443563638236\n",
      "step = 57600 , loss value = 1.2759183554815787\n",
      "step = 58000 , loss value = 1.2588315212175127\n",
      "step = 58400 , loss value = 1.1899169660714888\n",
      "step = 58800 , loss value = 1.2853166937756277\n",
      "step = 59200 , loss value = 1.1893817260128605\n",
      "step = 59600 , loss value = 1.3759360818892614\n",
      "step = 0 , loss value = 1.2958734080311163\n",
      "step = 400 , loss value = 1.317510283959235\n",
      "step = 800 , loss value = 1.2082623313889644\n",
      "step = 1200 , loss value = 1.1927966826068488\n",
      "step = 1600 , loss value = 1.2037211478637562\n",
      "step = 2000 , loss value = 4.858631016383598\n",
      "step = 2400 , loss value = 1.2806546867243294\n",
      "step = 2800 , loss value = 1.2288247544741824\n",
      "step = 3200 , loss value = 1.2241706884724752\n",
      "step = 3600 , loss value = 1.113925107427962\n",
      "step = 4000 , loss value = 1.360926240855467\n",
      "step = 4400 , loss value = 1.2878671096793002\n",
      "step = 4800 , loss value = 1.1152345596703905\n",
      "step = 5200 , loss value = 1.1551282769794147\n",
      "step = 5600 , loss value = 1.9578722173236798\n",
      "step = 6000 , loss value = 1.3130896462229682\n",
      "step = 6400 , loss value = 1.3821726486006898\n",
      "step = 6800 , loss value = 1.2181941938167848\n",
      "step = 7200 , loss value = 1.120654570535598\n",
      "step = 7600 , loss value = 1.3114001103838022\n",
      "step = 8000 , loss value = 1.394777910767302\n",
      "step = 8400 , loss value = 1.1445079635610897\n",
      "step = 8800 , loss value = 1.3324043774056915\n",
      "step = 9200 , loss value = 1.3775437040150056\n",
      "step = 9600 , loss value = 1.343797811344478\n",
      "step = 10000 , loss value = 1.343184593636816\n",
      "step = 10400 , loss value = 1.1464328060695599\n",
      "step = 10800 , loss value = 1.1028684066020615\n",
      "step = 11200 , loss value = 1.2384585843694433\n",
      "step = 11600 , loss value = 4.481317404525353\n",
      "step = 12000 , loss value = 1.2098876796271112\n",
      "step = 12400 , loss value = 1.1405918230652783\n",
      "step = 12800 , loss value = 1.2197805672435102\n",
      "step = 13200 , loss value = 1.241196728575289\n",
      "step = 13600 , loss value = 1.4477598981857018\n",
      "step = 14000 , loss value = 1.1308274975434711\n",
      "step = 14400 , loss value = 1.2652405908010795\n",
      "step = 14800 , loss value = 1.215385389877048\n",
      "step = 15200 , loss value = 1.4935175927703255\n",
      "step = 15600 , loss value = 1.3771171953704262\n",
      "step = 16000 , loss value = 1.2144456589430663\n",
      "step = 16400 , loss value = 1.3229624526685053\n",
      "step = 16800 , loss value = 1.3986312753140393\n",
      "step = 17200 , loss value = 1.1834036167715578\n",
      "step = 17600 , loss value = 1.221055997157237\n",
      "step = 18000 , loss value = 1.2247372177644094\n",
      "step = 18400 , loss value = 1.160975403976434\n",
      "step = 18800 , loss value = 1.1572837941032148\n",
      "step = 19200 , loss value = 1.2503666489214025\n",
      "step = 19600 , loss value = 1.130155797415531\n",
      "step = 20000 , loss value = 1.2536012695169259\n",
      "step = 20400 , loss value = 1.3957218048611721\n",
      "step = 20800 , loss value = 1.26911250401615\n",
      "step = 21200 , loss value = 1.1984477822502528\n",
      "step = 21600 , loss value = 1.3473449433131697\n",
      "step = 22000 , loss value = 1.2819221645958778\n",
      "step = 22400 , loss value = 1.1524647735281992\n",
      "step = 22800 , loss value = 1.2346090931561753\n",
      "step = 23200 , loss value = 1.288789754529257\n",
      "step = 23600 , loss value = 1.2038990417827509\n",
      "step = 24000 , loss value = 1.1912096233263554\n",
      "step = 24400 , loss value = 1.315660844981709\n",
      "step = 24800 , loss value = 1.196827585680579\n",
      "step = 25200 , loss value = 1.243799003016747\n",
      "step = 25600 , loss value = 1.158834175296034\n",
      "step = 26000 , loss value = 1.2448961800665574\n",
      "step = 26400 , loss value = 1.411952183266438\n",
      "step = 26800 , loss value = 1.4035424538039212\n",
      "step = 27200 , loss value = 1.1572734668678373\n",
      "step = 27600 , loss value = 1.3461252463266427\n",
      "step = 28000 , loss value = 1.1922311659713039\n",
      "step = 28400 , loss value = 1.3756259497409753\n",
      "step = 28800 , loss value = 1.2423138506002869\n",
      "step = 29200 , loss value = 1.3978727504234605\n",
      "step = 29600 , loss value = 1.2153587678818527\n",
      "step = 30000 , loss value = 1.316149189119622\n",
      "step = 30400 , loss value = 1.181600222148614\n",
      "step = 30800 , loss value = 1.1887120867711933\n",
      "step = 31200 , loss value = 1.1783872431497189\n",
      "step = 31600 , loss value = 1.0779342514246402\n",
      "step = 32000 , loss value = 1.1851090982284866\n",
      "step = 32400 , loss value = 1.1755535862841637\n",
      "step = 32800 , loss value = 1.309546925571666\n",
      "step = 33200 , loss value = 1.2252608072190052\n",
      "step = 33600 , loss value = 1.082346710648676\n",
      "step = 34000 , loss value = 1.2415565206496044\n",
      "step = 34400 , loss value = 1.244803954594809\n",
      "step = 34800 , loss value = 1.462616386208899\n",
      "step = 35200 , loss value = 1.278643915510822\n",
      "step = 35600 , loss value = 1.2053042389024418\n",
      "step = 36000 , loss value = 1.1981935548718903\n",
      "step = 36400 , loss value = 1.221339236811972\n",
      "step = 36800 , loss value = 1.2004708997928275\n",
      "step = 37200 , loss value = 1.159011176807225\n",
      "step = 37600 , loss value = 1.1739381964787334\n",
      "step = 38000 , loss value = 1.1882030636820065\n",
      "step = 38400 , loss value = 1.3404804675824702\n",
      "step = 38800 , loss value = 1.2481731629886168\n",
      "step = 39200 , loss value = 1.3090959889341702\n",
      "step = 39600 , loss value = 3.819900592447368\n",
      "step = 40000 , loss value = 1.3586060231165051\n",
      "step = 40400 , loss value = 1.3149317497369601\n",
      "step = 40800 , loss value = 1.2053592124689085\n",
      "step = 41200 , loss value = 1.192255685201641\n",
      "step = 41600 , loss value = 1.2400248930297018\n",
      "step = 42000 , loss value = 1.263939522368236\n",
      "step = 42400 , loss value = 1.2123978525501267\n",
      "step = 42800 , loss value = 1.357170922988422\n",
      "step = 43200 , loss value = 1.2033037573779435\n",
      "step = 43600 , loss value = 1.1955247230362867\n",
      "step = 44000 , loss value = 1.3304662403713956\n",
      "step = 44400 , loss value = 1.3626314165391935\n",
      "step = 44800 , loss value = 1.1687910144122786\n",
      "step = 45200 , loss value = 1.4672852877247142\n",
      "step = 45600 , loss value = 1.3257097557806161\n",
      "step = 46000 , loss value = 1.2907956648610819\n",
      "step = 46400 , loss value = 1.1689834372028378\n",
      "step = 46800 , loss value = 1.2018253109843782\n",
      "step = 47200 , loss value = 1.2561505576407421\n",
      "step = 47600 , loss value = 15.11215645198703\n",
      "step = 48000 , loss value = 1.3002123132459495\n",
      "step = 48400 , loss value = 1.3486214421199363\n",
      "step = 48800 , loss value = 1.1762357643018417\n",
      "step = 49200 , loss value = 1.1185140730277983\n",
      "step = 49600 , loss value = 1.1029881736409792\n",
      "step = 50000 , loss value = 1.2672547222766068\n",
      "step = 50400 , loss value = 1.2755261977218721\n",
      "step = 50800 , loss value = 1.4205641383811864\n",
      "step = 51200 , loss value = 1.2432026158403149\n",
      "step = 51600 , loss value = 1.1614610429789536\n",
      "step = 52000 , loss value = 1.1390237505423193\n",
      "step = 52400 , loss value = 1.426892456502423\n",
      "step = 52800 , loss value = 6.448539656135622\n",
      "step = 53200 , loss value = 1.2894392390671072\n",
      "step = 53600 , loss value = 1.2053318071108927\n",
      "step = 54000 , loss value = 1.3567791594150675\n",
      "step = 54400 , loss value = 1.3454215202123567\n",
      "step = 54800 , loss value = 1.3098995401362687\n",
      "step = 55200 , loss value = 1.2599913874036883\n",
      "step = 55600 , loss value = 1.3059952535934771\n",
      "step = 56000 , loss value = 1.240266605410711\n",
      "step = 56400 , loss value = 1.2891142012707533\n",
      "step = 56800 , loss value = 16.270491471912656\n",
      "step = 57200 , loss value = 1.3012842844027324\n",
      "step = 57600 , loss value = 1.329139678642372\n",
      "step = 58000 , loss value = 1.3367815574264064\n",
      "step = 58400 , loss value = 1.249128500902097\n",
      "step = 58800 , loss value = 1.3120008817409103\n",
      "step = 59200 , loss value = 1.2666911672857086\n",
      "step = 59600 , loss value = 1.3836405583928928\n",
      "step = 0 , loss value = 1.2963261585312373\n",
      "step = 400 , loss value = 1.3285545660267428\n",
      "step = 800 , loss value = 1.2603908566121744\n",
      "step = 1200 , loss value = 1.301440657042093\n",
      "step = 1600 , loss value = 1.238835895954447\n",
      "step = 2000 , loss value = 6.968708618762839\n",
      "step = 2400 , loss value = 1.2664594292028692\n",
      "step = 2800 , loss value = 1.2468312225389138\n",
      "step = 3200 , loss value = 1.273297188400489\n",
      "step = 3600 , loss value = 1.2072530460646562\n",
      "step = 4000 , loss value = 1.4011363036878552\n",
      "step = 4400 , loss value = 1.35073359267508\n",
      "step = 4800 , loss value = 1.1664772905375094\n",
      "step = 5200 , loss value = 1.1705356561585747\n",
      "step = 5600 , loss value = 2.965446375073281\n",
      "step = 6000 , loss value = 1.3426912050979385\n",
      "step = 6400 , loss value = 1.4451642437407872\n",
      "step = 6800 , loss value = 1.2583273762006026\n",
      "step = 7200 , loss value = 1.1705711701600472\n",
      "step = 7600 , loss value = 1.2912856272490056\n",
      "step = 8000 , loss value = 1.3923945846497092\n",
      "step = 8400 , loss value = 1.1394472483474132\n",
      "step = 8800 , loss value = 1.359455551816898\n",
      "step = 9200 , loss value = 1.4857665231877273\n",
      "step = 9600 , loss value = 1.488081269040647\n",
      "step = 10000 , loss value = 1.4049883720175034\n",
      "step = 10400 , loss value = 1.2100442722293283\n",
      "step = 10800 , loss value = 1.2014587952918319\n",
      "step = 11200 , loss value = 1.2651588047943678\n",
      "step = 11600 , loss value = 6.7407818170996\n",
      "step = 12000 , loss value = 1.23461140080157\n",
      "step = 12400 , loss value = 1.2698744012434577\n",
      "step = 12800 , loss value = 1.3161046004794008\n",
      "step = 13200 , loss value = 1.2339181633321705\n",
      "step = 13600 , loss value = 1.4255901248542917\n",
      "step = 14000 , loss value = 1.1686986937200226\n",
      "step = 14400 , loss value = 1.253454399054744\n",
      "step = 14800 , loss value = 1.25491687784697\n",
      "step = 15200 , loss value = 1.512494354075933\n",
      "step = 15600 , loss value = 1.445188454952795\n",
      "step = 16000 , loss value = 1.2022129159643722\n",
      "step = 16400 , loss value = 1.3535369882638504\n",
      "step = 16800 , loss value = 1.387499790592559\n",
      "step = 17200 , loss value = 1.166397763837955\n",
      "step = 17600 , loss value = 1.2369060025215364\n",
      "step = 18000 , loss value = 1.240817196460542\n",
      "step = 18400 , loss value = 1.1617638994909665\n",
      "step = 18800 , loss value = 1.215472944108204\n",
      "step = 19200 , loss value = 1.2396043621756483\n",
      "step = 19600 , loss value = 1.140540908925515\n",
      "step = 20000 , loss value = 1.23188322646046\n",
      "step = 20400 , loss value = 1.4532993246490333\n",
      "step = 20800 , loss value = 1.2893667016011716\n",
      "step = 21200 , loss value = 1.233778786260311\n",
      "step = 21600 , loss value = 1.3453807688464723\n",
      "step = 22000 , loss value = 1.2508263878108\n",
      "step = 22400 , loss value = 1.2413903078393433\n",
      "step = 22800 , loss value = 1.2264461578856216\n",
      "step = 23200 , loss value = 1.27236745657671\n",
      "step = 23600 , loss value = 1.24071013919783\n",
      "step = 24000 , loss value = 1.2277766891725777\n",
      "step = 24400 , loss value = 1.416826717405967\n",
      "step = 24800 , loss value = 1.1754581733577942\n",
      "step = 25200 , loss value = 1.229921955776553\n",
      "step = 25600 , loss value = 1.185715718977453\n",
      "step = 26000 , loss value = 1.274146449265913\n",
      "step = 26400 , loss value = 1.2971450238395743\n",
      "step = 26800 , loss value = 1.3958249343452962\n",
      "step = 27200 , loss value = 1.2098933570931816\n",
      "step = 27600 , loss value = 1.2810217187628825\n",
      "step = 28000 , loss value = 1.2460301248581733\n",
      "step = 28400 , loss value = 1.3336431217223434\n",
      "step = 28800 , loss value = 1.2512899534833497\n",
      "step = 29200 , loss value = 1.3619818733051356\n",
      "step = 29600 , loss value = 1.2661941318163492\n",
      "step = 30000 , loss value = 1.2800627358028704\n",
      "step = 30400 , loss value = 1.1687579697145485\n",
      "step = 30800 , loss value = 1.315076269509856\n",
      "step = 31200 , loss value = 1.2342481507281922\n",
      "step = 31600 , loss value = 1.0874243936136367\n",
      "step = 32000 , loss value = 1.1766012608165053\n",
      "step = 32400 , loss value = 1.15033940581181\n",
      "step = 32800 , loss value = 1.4237067219610695\n",
      "step = 33200 , loss value = 1.2420558758025233\n",
      "step = 33600 , loss value = 1.1206712935535739\n",
      "step = 34000 , loss value = 1.2736471719456584\n",
      "step = 34400 , loss value = 1.2442584397069663\n",
      "step = 34800 , loss value = 1.087635217513319\n",
      "step = 35200 , loss value = 1.2949578225703147\n",
      "step = 35600 , loss value = 1.200520623507978\n",
      "step = 36000 , loss value = 1.2031278591833645\n",
      "step = 36400 , loss value = 1.289063643423818\n",
      "step = 36800 , loss value = 1.2009947188640604\n",
      "step = 37200 , loss value = 1.110613986773638\n",
      "step = 37600 , loss value = 1.2801706078933637\n",
      "step = 38000 , loss value = 1.2173380616444138\n",
      "step = 38400 , loss value = 1.358728621105731\n",
      "step = 38800 , loss value = 1.2525375060315251\n",
      "step = 39200 , loss value = 1.3545101827204675\n",
      "step = 39600 , loss value = 3.366084431241526\n",
      "step = 40000 , loss value = 1.423225096643554\n",
      "step = 40400 , loss value = 1.3245801839596\n",
      "step = 40800 , loss value = 1.2745259268205844\n",
      "step = 41200 , loss value = 1.2174480181099452\n",
      "step = 41600 , loss value = 1.2452566414850508\n",
      "step = 42000 , loss value = 1.3365570150102892\n",
      "step = 42400 , loss value = 1.2138968369646486\n",
      "step = 42800 , loss value = 1.3607279414406106\n",
      "step = 43200 , loss value = 1.2187130825975983\n",
      "step = 43600 , loss value = 1.2200147371911012\n",
      "step = 44000 , loss value = 1.3468128419994674\n",
      "step = 44400 , loss value = 1.2943715370470568\n",
      "step = 44800 , loss value = 1.1561979019837978\n",
      "step = 45200 , loss value = 1.4927417074314857\n",
      "step = 45600 , loss value = 1.2807070246105863\n",
      "step = 46000 , loss value = 1.3348491410964258\n",
      "step = 46400 , loss value = 1.1217746304700305\n",
      "step = 46800 , loss value = 1.1870515034753057\n",
      "step = 47200 , loss value = 1.1962552159622855\n",
      "step = 47600 , loss value = 10.934771553618294\n",
      "step = 48000 , loss value = 1.2887567418652852\n",
      "step = 48400 , loss value = 1.3184971176891034\n",
      "step = 48800 , loss value = 1.2834675552136774\n",
      "step = 49200 , loss value = 1.1774956469641735\n",
      "step = 49600 , loss value = 1.0843377351786962\n",
      "step = 50000 , loss value = 1.3438708823776375\n",
      "step = 50400 , loss value = 1.2850719055085278\n",
      "step = 50800 , loss value = 1.4159051056575551\n",
      "step = 51200 , loss value = 2.33294397051203\n",
      "step = 51600 , loss value = 1.1397338167317472\n",
      "step = 52000 , loss value = 1.165818809791725\n",
      "step = 52400 , loss value = 1.4224773803910136\n",
      "step = 52800 , loss value = 9.557817368720139\n",
      "step = 53200 , loss value = 1.3456532319109646\n",
      "step = 53600 , loss value = 1.2279420626907347\n",
      "step = 54000 , loss value = 1.363800517261102\n",
      "step = 54400 , loss value = 1.292184656671616\n",
      "step = 54800 , loss value = 1.3935924670039015\n",
      "step = 55200 , loss value = 1.2272022799445517\n",
      "step = 55600 , loss value = 1.299613282532543\n",
      "step = 56000 , loss value = 1.2599138725852819\n",
      "step = 56400 , loss value = 1.2494051453654063\n",
      "step = 56800 , loss value = 16.921095120559464\n",
      "step = 57200 , loss value = 1.2872193447394091\n",
      "step = 57600 , loss value = 1.315732898077581\n",
      "step = 58000 , loss value = 1.2775407706052293\n",
      "step = 58400 , loss value = 1.2754088126528857\n",
      "step = 58800 , loss value = 1.3266138402233123\n",
      "step = 59200 , loss value = 1.3191925755549483\n",
      "step = 59600 , loss value = 1.3641833740224056\n",
      "\n",
      " elapsed time = 0:00:32.595190\n"
     ]
    }
   ],
   "source": [
    "input_nodes, hidden_nodes, output_nodes = 784, 100, 10\n",
    "learning_rate = 0.3\n",
    "epochs = 5\n",
    "\n",
    "bp = Backpropagation(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for step in range(len(training_data)):\n",
    "        target_data = np.zeros(output_nodes) + 0.01\n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "\n",
    "        input_data = (training_data[step, 1:] / 255.0 * 0.99) + 0.01\n",
    "\n",
    "        bp.train(np.array(input_data, ndmin=2), np.array(target_data, ndmin=2))\n",
    "\n",
    "        if step % 400 == 0:\n",
    "            print(\"step =\", step, \", loss value =\", bp.loss_val())\n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"\\n elapsed time =\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current a accuracy = 96.43  %\n"
     ]
    }
   ],
   "source": [
    "bp.accuracy(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = r\"ML_YouTube_test_number\\test3_1.png\"\n",
    "\n",
    "with Image.open(image_path) as img:\n",
    "    img = img.resize((28, 28))\n",
    "    img = img.convert('L')\n",
    "\n",
    "image_array = np.array(img)\n",
    "image_array = (image_array / 255.0 * 0.99) + 0.01\n",
    "image_data = np.array(image_array.flatten(), ndmin=2)\n",
    "\n",
    "predicted_label = bp.predict(image_data)\n",
    "print(\"Predicted Label: \", predicted_label)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f'Predicted: {predicted_label}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
