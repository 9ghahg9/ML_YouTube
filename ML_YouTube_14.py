# Linear Regression(II)
## Gradient Decent Algorithm: It refers to an algorithm that gradually reduces the value 
##                            of the loss function.
## <=> The slope W value mush be minimized.
## ==> W = W - alpha * ( dE(W, b) / dW ), alpha is a learning rate.
##     b = b - alpha * ( dE(W, b) / db )
